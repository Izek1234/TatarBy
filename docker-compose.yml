
services:
  frontend:
    build: ./hahaton
    container_name: frontend
    ports:
      - "3000:3000"
    environment:
      HOST: 0.0.0.0
      PORT: 3000
    networks:
      - app-network
    restart: unless-stopped

  tat-diffusion:
    build: ./sd-back  
    container_name: tat-diffusion-api
    ports:
      - "8000:8000"
    env_file:
      - .env
    volumes:
      - ./model_cache:/app/model_cache 
    environment:
      - HF_HUB_CACHE=/app/model_cache
      - TRANSFORMERS_CACHE=/app/model_cache
      - DEVICE=cuda  
    restart: unless-stopped

  tatgpt-api:
    build: ./llm-back  
    container_name: tatgpt-api
    ports:
      - "8001:8001"
    env_file:
      - .env
    volumes:
      - ./llm-back/main.py:/app/main.py         
      - ./llm-back/requirements.txt:/app/requirements.txt
      - ./model_cache:/app/model_cache           
    environment:
      - HF_HUB_CACHE=/app/model_cache
      - TRANSFORMERS_CACHE=/app/model_cache
    restart: unless-stopped

networks:
  app-network:
    driver: bridge